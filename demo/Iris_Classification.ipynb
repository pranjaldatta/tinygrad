{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World!\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello World!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tinygrad.core import Tensor\n",
    "from tinygrad.nn import SimpleMLP\n",
    "from tinygrad.losses import MSELoss\n",
    "from tinygrad.optimizers import SimpleSGD, Adam\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import math\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"IrisFlower/iris.data\"\n",
    "\n",
    "dataset = []\n",
    "with open(path) as fp:\n",
    "    file = fp.read().splitlines()\n",
    "file = [line.split(\",\") for line in file]\n",
    "file = file[:150]\n",
    "\n",
    "dataset = [[list(map(float, line[:4])), line[4]] for line in file]\n",
    "\n",
    "classes = ['Iris-setosa', 'Iris-versicolor', 'Iris-virginica']\n",
    "dataset = [[row[0], classes.index(row[1])] for row in dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids = [random.sample(range(i,i+50), k=40) for i in [0, 50, 100]]\n",
    "train_ids = [item for sublist in train_ids for item in sublist]\n",
    "\n",
    "val_ids = [i for i in range(150) if i not in train_ids]\n",
    "\n",
    "trainset = [dataset[i] for i in train_ids]\n",
    "valset = [dataset[i] for i in val_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainset size:  120\n",
      "Valset size:  30\n"
     ]
    }
   ],
   "source": [
    "print(\"Trainset size: \", len(trainset))\n",
    "print(\"Valset size: \", len(valset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleMLP(\n",
      "Linear(ins:4 outs:8 num_parameters:40)\n",
      "Linear(ins:8 outs:8 num_parameters:72)\n",
      "Linear(ins:8 outs:1 num_parameters:9)\n",
      ")\n",
      "Number of parameters: 121\n"
     ]
    }
   ],
   "source": [
    "# now we define the model \n",
    "# we are going to define a 4, 8, 8, 1 model \n",
    "model = SimpleMLP(4, 1, [8, 8])\n",
    "\n",
    "# temporary fix to make last layer nonlin=False\n",
    "for i, layer in enumerate(model.layers):\n",
    "    if i == len(model.layers) - 1:\n",
    "        for n in layer.neurons:\n",
    "            n.nonlin = False\n",
    "\n",
    "# print the model summary\n",
    "model.summary()\n",
    "\n",
    "#total parameters\n",
    "print(\"Number of parameters:\", len(model.parameters()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For epoch: 0, loss: 60.130727777643884\n",
      "For epoch: 5, loss: 0.7712787610804327\n",
      "For epoch: 10, loss: 0.46219525996032396\n",
      "For epoch: 15, loss: 0.2891760491648806\n",
      "For epoch: 20, loss: 0.19942535062747227\n",
      "For epoch: 25, loss: 0.150112504230865\n",
      "For epoch: 30, loss: 0.12284523493826181\n",
      "For epoch: 35, loss: 0.10781866924615685\n",
      "For epoch: 40, loss: 0.0991380179068486\n",
      "For epoch: 45, loss: 0.09376738503437174\n",
      "For epoch: 50, loss: 0.09042586739242538\n",
      "For epoch: 55, loss: 0.08824914359129224\n",
      "For epoch: 60, loss: 0.08639046674862737\n",
      "For epoch: 65, loss: 0.08460879565532758\n",
      "For epoch: 70, loss: 0.0831564368012693\n",
      "For epoch: 75, loss: 0.08190254679564679\n",
      "For epoch: 80, loss: 0.08077636720262737\n",
      "For epoch: 85, loss: 0.07996345335703128\n",
      "For epoch: 90, loss: 0.07927067924074244\n",
      "For epoch: 95, loss: 0.07872298038383277\n",
      "For epoch: 100, loss: 0.07819942097592325\n",
      "For epoch: 105, loss: 0.07769802619523128\n",
      "For epoch: 110, loss: 0.0772171511871068\n",
      "For epoch: 115, loss: 0.07676121708701591\n",
      "For epoch: 120, loss: 0.07633767714330496\n",
      "For epoch: 125, loss: 0.07597976945963703\n",
      "For epoch: 130, loss: 0.0756449557690608\n",
      "For epoch: 135, loss: 0.0753228884178196\n",
      "For epoch: 140, loss: 0.07506717992454029\n",
      "For epoch: 145, loss: 0.07482029399265484\n",
      "For epoch: 150, loss: 0.07458212649121171\n",
      "For epoch: 155, loss: 0.07435173698706234\n",
      "For epoch: 160, loss: 0.0741283463747425\n",
      "For epoch: 165, loss: 0.07390946052213818\n",
      "For epoch: 170, loss: 0.07369540397511941\n",
      "For epoch: 175, loss: 0.07349779622346411\n",
      "For epoch: 180, loss: 0.07332755095700816\n",
      "For epoch: 185, loss: 0.07316059722025403\n",
      "For epoch: 190, loss: 0.07299669911069315\n",
      "For epoch: 195, loss: 0.0728356630672427\n",
      "For epoch: 200, loss: 0.07267750105386706\n",
      "For epoch: 205, loss: 0.0725236254337729\n",
      "For epoch: 210, loss: 0.07236867678682495\n",
      "For epoch: 215, loss: 0.07220559342773945\n",
      "For epoch: 220, loss: 0.07204614806987507\n",
      "For epoch: 225, loss: 0.07189017091686632\n",
      "For epoch: 230, loss: 0.07173182791959638\n",
      "For epoch: 235, loss: 0.07157155150609898\n",
      "For epoch: 240, loss: 0.07141360366131755\n",
      "For epoch: 245, loss: 0.07126744324220183\n",
      "For epoch: 250, loss: 0.0711245255936506\n",
      "For epoch: 255, loss: 0.07098513816269603\n",
      "For epoch: 260, loss: 0.07084790977719356\n",
      "For epoch: 265, loss: 0.07071030997364584\n",
      "For epoch: 270, loss: 0.07057442775690563\n",
      "For epoch: 275, loss: 0.07043954859262685\n",
      "For epoch: 280, loss: 0.07030688427361181\n",
      "For epoch: 285, loss: 0.0701763073033091\n",
      "For epoch: 290, loss: 0.07004736676285056\n",
      "For epoch: 295, loss: 0.06991999508568754\n",
      "For epoch: 300, loss: 0.06979413164911379\n",
      "For epoch: 305, loss: 0.06967122470178672\n",
      "For epoch: 310, loss: 0.06955036232127099\n",
      "For epoch: 315, loss: 0.06943076759432995\n",
      "For epoch: 320, loss: 0.06931240162192018\n",
      "For epoch: 325, loss: 0.06919423302445522\n",
      "For epoch: 330, loss: 0.06907681671043091\n",
      "For epoch: 335, loss: 0.06896108290279084\n",
      "For epoch: 340, loss: 0.06884583043375106\n",
      "For epoch: 345, loss: 0.06873101895938434\n",
      "For epoch: 350, loss: 0.06861766313106081\n",
      "For epoch: 355, loss: 0.06850549394898423\n",
      "For epoch: 360, loss: 0.06839483130993054\n",
      "For epoch: 365, loss: 0.0682852866283725\n",
      "For epoch: 370, loss: 0.0681769094775759\n",
      "For epoch: 375, loss: 0.06806973028272544\n",
      "For epoch: 380, loss: 0.06796371102543812\n",
      "For epoch: 385, loss: 0.06785880972007027\n",
      "For epoch: 390, loss: 0.06775496135098898\n",
      "For epoch: 395, loss: 0.06765211139742638\n",
      "For epoch: 400, loss: 0.06755021340210553\n",
      "For epoch: 405, loss: 0.06744922720525709\n",
      "For epoch: 410, loss: 0.06734911763627985\n",
      "For epoch: 415, loss: 0.06725212633746329\n",
      "For epoch: 420, loss: 0.0671567786668804\n",
      "For epoch: 425, loss: 0.06706208105820381\n",
      "For epoch: 430, loss: 0.06696801613278114\n",
      "For epoch: 435, loss: 0.0668745683021793\n",
      "For epoch: 440, loss: 0.06678172334345761\n",
      "For epoch: 445, loss: 0.06668946811083286\n",
      "For epoch: 450, loss: 0.06659779033417144\n",
      "For epoch: 455, loss: 0.06650667847398921\n",
      "For epoch: 460, loss: 0.066416121614135\n",
      "For epoch: 465, loss: 0.06632610938025627\n",
      "For epoch: 470, loss: 0.06623663187636672\n",
      "For epoch: 475, loss: 0.06614767963444311\n",
      "For epoch: 480, loss: 0.06605924357361978\n",
      "For epoch: 485, loss: 0.06597131496659786\n",
      "For epoch: 490, loss: 0.06588403014439544\n",
      "For epoch: 495, loss: 0.06579729334177932\n"
     ]
    }
   ],
   "source": [
    "epochs = 500\n",
    "lr = 0.001\n",
    "\n",
    "optimizer = SimpleSGD(model.parameters(), lr=lr)\n",
    "loss_fn = MSELoss\n",
    "\n",
    "X = [list(map(Tensor, x[0])) for x in trainset]\n",
    "Y = [Tensor(x[1]) for x in trainset]\n",
    "\n",
    "losslist = [] #to store losses\n",
    "\n",
    "for i in range(epochs):\n",
    "    \n",
    "    preds = list(map(model, X)) # we do gradient descent\n",
    "    \n",
    "    loss = loss_fn(preds, Y)\n",
    "    \n",
    "    model.zero_grad()\n",
    "    loss.backward()\n",
    "    \n",
    "    optimizer.step()\n",
    "    \n",
    "    if i%5 == 0:\n",
    "        print(\"For epoch: {}, loss: {}\".format(i, loss.data))\n",
    "        losslist.append(loss.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7ff80e2ab908>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losslist, range(len(losslist)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = [list(map(Tensor, x[0])) for x in valset]\n",
    "Y_val = [Tensor(x[1]) for x in valset]\n",
    "\n",
    "preds = list(map(model, X_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss:  0.047896011766359416\n"
     ]
    }
   ],
   "source": [
    "val_loss = loss_fn(preds, Y_val)\n",
    "print(\"val loss: \", val_loss.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx: 0, predicted: 0, true value: 0\n",
      "idx: 2, predicted: 0, true value: 0\n",
      "idx: 4, predicted: 0, true value: 0\n",
      "idx: 6, predicted: 0, true value: 0\n",
      "idx: 8, predicted: 0, true value: 0\n",
      "idx: 10, predicted: 1, true value: 1\n",
      "idx: 12, predicted: 1, true value: 1\n",
      "idx: 14, predicted: 1, true value: 1\n",
      "idx: 16, predicted: 2, true value: 1\n",
      "idx: 18, predicted: 1, true value: 1\n",
      "idx: 20, predicted: 2, true value: 2\n",
      "idx: 22, predicted: 2, true value: 2\n",
      "idx: 24, predicted: 2, true value: 2\n",
      "idx: 26, predicted: 2, true value: 2\n",
      "idx: 28, predicted: 2, true value: 2\n",
      "Validation accuracy: 96.66666666666667%\n"
     ]
    }
   ],
   "source": [
    "accuracy = 0\n",
    "idx = 0\n",
    "for pi, yi in zip(preds, Y_val):\n",
    "    if idx % 2 == 0:\n",
    "        print(\"idx: {}, predicted: {}, true value: {}\".format(idx, round((pi.data)), yi.data))\n",
    "    if round(pi.data) == yi.data:\n",
    "        accuracy += 1\n",
    "    idx += 1\n",
    "print(\"Validation accuracy: {}%\".format((accuracy/len(Y_val)) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we save the model \n",
    "model.save(\"saved_models/model_SGD_96.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx: 0, predicted: 0, true value: 0\n",
      "idx: 3, predicted: 0, true value: 0\n",
      "idx: 6, predicted: 0, true value: 0\n",
      "idx: 9, predicted: 0, true value: 0\n",
      "idx: 12, predicted: 1, true value: 1\n",
      "idx: 15, predicted: 1, true value: 1\n",
      "idx: 18, predicted: 1, true value: 1\n",
      "idx: 21, predicted: 2, true value: 2\n",
      "idx: 24, predicted: 2, true value: 2\n",
      "idx: 27, predicted: 2, true value: 2\n",
      "Validation accuracy: 96.66666666666667%\n"
     ]
    }
   ],
   "source": [
    "# now we load the weigths and check \n",
    "# we instantiate a new model\n",
    "val_model = SimpleMLP(4, 1, [8, 8])\n",
    "val_model.load_pkl(\"saved_models/model_SGD_96.pkl\")\n",
    "\n",
    "preds = list(map(val_model, X_val))\n",
    "\n",
    "accuracy = 0\n",
    "idx = 0\n",
    "for pi, yi in zip(preds, Y_val):\n",
    "    if idx % 3 == 0:\n",
    "        print(\"idx: {}, predicted: {}, true value: {}\".format(idx, round((pi.data)), yi.data))\n",
    "    if round(pi.data) == yi.data:\n",
    "        accuracy += 1\n",
    "    idx += 1\n",
    "print(\"Validation accuracy: {}%\".format((accuracy/len(Y_val)) * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.1 64-bit ('tinygrad': conda)",
   "language": "python",
   "name": "python37164bittinygradconda67a60def8dcb4c8aa34048bd4870bafd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
